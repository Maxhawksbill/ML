# Homework


## Інсталяція залежностей

```bash
pip install -r requirements.txt
```


## Завдання

1. Допишіть в файлі `kfold.py` функції `kfold_cross_validation` та `evaluate_accuracy` для того щоб порахувати точність роботи KNN алгоритму.

Done

2. Порахуйте для різних `k` в `KNN` точність на **тестовому** датасеті і запишіть в `README.md`, `k` беріть з таблички нижче

 k | Accuracy
---|----------
 3 | ???
 4 | ???
 5 | ???
 6 | ???
 7 | ???
 9 | ???
10 | ???
15 | ???
20 | ???
21 | ???
40 | ???
41 | ???

     k Accuracy
0    3     0.85
1    4     0.86
2    5     0.86
3    6     0.86
4    7     0.85
5    9     0.84
6   10     0.84
7   15     0.82
8   20     0.81
9   21     0.81
10  40     0.78
11  41     0.78
Best k from cross-validation: 4
Test Accuracy with k=4: 0.83

Які можна зробити висновки про вибір `k`?
### Спостережувані тренди:

**Початкове збільшення та стабільність:**
- Для малих значень k (від 3 до 6) точність злегка збільшується або залишається стабільною.
  - Наприклад, k = 3 дає точність 0.85, в той час як k = 4, k = 5 та k = 6 дають трохи вищу точність (0.86). Це вказує на те, що малі значення k дають хороші прогнози.

**Стабільність:**
- Між k = 4 і k = 6 точність стабільно дорівнює 0.86, що свідчить про те, що збільшення k в межах цього діапазону не дає значних покращень точності.
- Це вказує на те, що діапазон k = 4 до k = 6 є оптимальним для цього набору даних і забезпечує стабільну точність.

**Зниження точності при збільшенні k:**
- Починаючи з k = 7 та вище, точність починає знижуватися. Наприклад:
  - k = 7 дає 0.85,
  - k = 9 дає 0.84,
  - k = 10 дає 0.84,
  - І з подальшим збільшенням k (до k = 40 та k = 41) точність знижується до 0.78.
- Зниження точності при збільшенні k свідчить про те, що розглядати занадто багато сусідів може призвести до того, що модель стане менш чутливою до тонких деталей даних, що призводить до "перегладжування" межі прийняття рішень.

### Висновки:

**Оптимальний діапазон для k:**
- Модель працює найкраще, коли k знаходиться між 4 і 6. У цьому діапазоні точність або стабільна, або трохи вища, ніж для інших значень k.
- Ці значення k здаються оптимальними для балансування між перекосом (bias) і варіативністю (variance).

**Ризик переобучення або недообучення:**
- Малі значення k (як, наприклад, 3) можуть призвести до високої варіативності (переобучення), коли модель буде надто чутлива до шуму в навчальних даних. Однак точність все ще досить висока для k = 3, що вказує на те, що це значення k не надто схильне до переобучення в цьому випадку.
- Великі значення k (як, наприклад, 20, 40, 41) ймовірно призведуть до високого перекосу (недообучення), коли модель стане занадто спрощеною і втратить здатність захоплювати нюанси даних.

**Стабільність:**
- Точність залишається відносно стабільною між k = 3 і k = 6, що робить ці значення хорошими кандидатами для подальших експериментів або налаштувань, оскільки немає значного покращення при збільшенні k.

### Рекомендація:
- Виберіть k = 4, k = 5 або k = 6 для оптимальної роботи, оскільки ці значення дають найвищу і найбільш стабільну точність. Однак, якщо ви віддаєте перевагу трохи меншому значенню k, то k = 3 також дає хороші результати.


3. Знайшовши найкращий `k` змініть `num_folds` (в `main()`) та подивіться чи в середньому точність на валідаційних датасетах схожа з точністю на тестовому датасеті.

Змінів num_folds=8, точність для тестовому датасеті залишилась приблизно такою ж, як для num_folds=5, але точність на валідційному впала на 1%. Але в середньмоу дуже близко: 0.86 - 0.83 для 5 та 0.86 - 0.82 для 8.

     k Accuracy     
0    3     0.86
1    4     0.86
2    5     0.85
3    6     0.86
4    7     0.85
5    9     0.85
6   10     0.85
7   15     0.83
8   20     0.82
9   21     0.81
10  40     0.78
11  41     0.78
Best k from cross-validation: 3
Test Accuracy with k=3: 0.82